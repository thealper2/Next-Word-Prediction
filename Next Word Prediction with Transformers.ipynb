{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5dc7a91-1eb9-448f-bc56-4945258e305f",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cab471f-3e43-4f1f-9b27-e58365e6b2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from transformers import (\n",
    "    BertTokenizer, BertForMaskedLM,\n",
    "    XLNetTokenizer, XLNetLMHeadModel,\n",
    "    XLMRobertaTokenizer, XLMRobertaForMaskedLM,\n",
    "    BartTokenizer, BartForConditionalGeneration,\n",
    "    ElectraTokenizer, ElectraForMaskedLM,\n",
    "    RobertaTokenizer, RobertaForMaskedLM,\n",
    "    GPT2Tokenizer, GPT2LMHeadModel\n",
    ")\n",
    "\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77037626-eb4e-486c-9abc-c81ecf8dc9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1566f8-926d-43ce-a389-a62018444e7f",
   "metadata": {},
   "source": [
    "# Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca6d4cc-e79f-49a2-a46b-f428440ba40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    0: \"bert-base-cased\",\n",
    "    1: \"xlnet-base-cased\",\n",
    "    2: \"xlm-roberta-base\",\n",
    "    3: \"facebook/bart-large\",\n",
    "    4: \"google/electra-small-generator\",\n",
    "    5: \"roberta-base\",\n",
    "    6: \"gpt2\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80318d4c-7c82-4222-80b4-cd37b94437dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = BertTokenizer.from_pretrained(MODELS[0])\n",
    "bert_model = BertForMaskedLM.from_pretrained(MODELS[0]).to(device).eval()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccfd38a-3873-483e-b854-da63c7116c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlnet_tokenizer = XLNetTokenizer.from_pretrained(MODELS[1])\n",
    "xlnet_model = XLNetLMHeadModel.from_pretrained(MODELS[1]).to(device).eval()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71560b1d-7314-4c6a-bb21-f61fcb4bdfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xlmroberta_tokenizer = XLMRobertaTokenizer.from_pretrained(MODELS[2])\n",
    "xlmroberta_model = XLMRobertaForMaskedLM.from_pretrained(MODELS[2]).to(device).eval()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520a0354-2688-4659-b4ee-fd64c37c5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_tokenizer = BartTokenizer.from_pretrained(MODELS[3])\n",
    "bart_model = BartForConditionalGeneration.from_pretrained(MODELS[3]).to(device).eval()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ff77d7-af82-4a04-9a0a-dfc8674943e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "electra_tokenizer = ElectraTokenizer.from_pretrained(MODELS[4])\n",
    "electra_model = ElectraForMaskedLM.from_pretrained(MODELS[4]).to(device).eval()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ab3e1e-5ec4-46b6-8042-90a3f1fb90e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_tokenizer = RobertaTokenizer.from_pretrained(MODELS[5])\n",
    "roberta_model = RobertaForMaskedLM.from_pretrained(MODELS[5]).to(device).eval()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ee3ba5-820d-431a-81c3-f0821281c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt2_tokenizer = GPT2Tokenizer.from_pretrained(MODELS[6])\n",
    "gpt2_model = GPT2LMHeadModel.from_pretrained(MODELS[6]).to(device).eval()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9f53a5-7668-4c33-bf2b-f02dbbf51b99",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Deep learning is\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24540be6-1c5a-4161-918f-e80bf32bebd8",
   "metadata": {},
   "source": [
    "# Greedy Search Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f2771-ae9b-42f1-84d8-8137758872eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def greedy_search_decoding(model_name, model, tokenizer, sentence, n_steps, choices_per_step):\n",
    "    input_ids = tokenizer(sentence, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "\n",
    "    iterations = []\n",
    "    for _ in range(n_steps):\n",
    "        output = model(input_ids=input_ids)\n",
    "        next_token_probs = torch.softmax(output.logits[0, -1, :], dim=-1)\n",
    "        \n",
    "        sorted_ids = torch.argsort(next_token_probs, dim=-1, descending=True)[:choices_per_step]\n",
    "        \n",
    "        iteration = {\n",
    "            \"Model\": model_name,\n",
    "            \"Input\": tokenizer.decode(input_ids[0], skip_special_tokens=True),\n",
    "            **{f\"Choice {i+1}\": f\"{tokenizer.decode(sorted_ids[i], skip_special_tokens=True)} ({100 * next_token_probs[sorted_ids[i]].item():.2f}%)\"\n",
    "               for i in range(choices_per_step)}\n",
    "        }\n",
    "\n",
    "        input_ids = torch.cat([input_ids, sorted_ids[0].unsqueeze(0).unsqueeze(0)], dim=-1)\n",
    "        iterations.append(iteration)\n",
    "\n",
    "    df = pd.DataFrame(iterations)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c1b8bf-4eaa-460f-9860-814fd5475d7c",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b4611b-c2c4-43e7-9ab1-d1664c24e0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_bert_df = greedy_search_decoding(\"BERT\", bert_model, bert_tokenizer, sentence, n_steps=5, choices_per_step=5)\n",
    "greedy_bert_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9d5c0b-d092-4c14-ad8c-e07fbd22d9ef",
   "metadata": {},
   "source": [
    "### XLNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231b1571-a8dc-489a-8a4e-bb9e4857d8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_xlnet_df = greedy_search_decoding(\"XLNET\", xlnet_model, xlnet_tokenizer, sentence, n_steps=5, choices_per_step=5)\n",
    "greedy_xlnet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92595c8e-b348-4a7a-9bf3-8e9aae341917",
   "metadata": {},
   "source": [
    "### XLM-RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20782906-f846-4581-a205-94c3a5104b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_xlmroberta_df = greedy_search_decoding(\"XLM-RoBERTa\", xlmroberta_model, xlmroberta_tokenizer, sentence, n_steps=5, choices_per_step=5)\n",
    "greedy_xlmroberta_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a72fb021-e32a-42f3-9800-ecc233507562",
   "metadata": {},
   "source": [
    "### BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa110fe-f7e3-4029-8905-b816a620f71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_bart_df = greedy_search_decoding(\"BART\", bart_model, bart_tokenizer, sentence, n_steps=5, choices_per_step=5)\n",
    "greedy_bart_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9eab79-74c8-40ca-9e17-a3808d08e073",
   "metadata": {},
   "source": [
    "### ELECTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88577129-7417-499e-9f4c-9852702acfb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_electra_df = greedy_search_decoding(\"ELECTRA\", electra_model, electra_tokenizer, sentence, n_steps=5, choices_per_step=5)\n",
    "greedy_electra_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0990467-5ebd-4fa0-850f-8b115c94c4de",
   "metadata": {},
   "source": [
    "### RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218112b0-587f-4195-b6ff-3013bfea7a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_roberta_df = greedy_search_decoding(\"RoBERTa\", roberta_model, roberta_tokenizer, sentence, n_steps=5, choices_per_step=5)\n",
    "greedy_roberta_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cabad1-2a43-40bf-aa57-e137073a9d53",
   "metadata": {},
   "source": [
    "### GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828f770f-cf42-4e45-8fa7-d48150de55ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_gpt2_df = greedy_search_decoding(\"GPT2\", gpt2_model, gpt2_tokenizer, sentence, n_steps=5, choices_per_step=5)\n",
    "greedy_gpt2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b58d2ba5-22a7-485c-8140-148635745678",
   "metadata": {},
   "source": [
    "# Beam Search Decoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a4dde7-1af4-4417-b8a0-3f8f2df87294",
   "metadata": {},
   "outputs": [],
   "source": [
    "def beam_search_decoding(model_name, model, tokenizer, sentence, n_steps=5, choices_per_step=5, beam_width=5):\n",
    "    input_ids = tokenizer(sentence, return_tensors=\"pt\")[\"input_ids\"].to(device)\n",
    "\n",
    "    iterations = []\n",
    "    beam = [(input_ids, 0.0)]\n",
    "\n",
    "    for step in range(n_steps):\n",
    "        candidates = []\n",
    "        for input_ids, beam_score in beam:\n",
    "            output = model(input_ids=input_ids)\n",
    "            next_token_logits = output.logits[0, -1, :]\n",
    "            next_token_probs = torch.log_softmax(next_token_logits, dim=-1)\n",
    "\n",
    "            for punct_token in [tokenizer.encode(t, add_special_tokens=False)[0] for t in string.punctuation]:\n",
    "                next_token_probs[punct_token] -= 100 \n",
    "\n",
    "            top_k_probs, top_k_ids = torch.topk(next_token_probs, beam_width)\n",
    "\n",
    "            token_id = top_k_ids[beam_width - 1].unsqueeze(0)\n",
    "            token_log_prob = top_k_probs[beam_width - 1].item()\n",
    "\n",
    "            new_input_ids = torch.cat([input_ids, token_id.unsqueeze(0)], dim=-1)\n",
    "            new_score = beam_score + token_log_prob\n",
    "            candidates.append((new_input_ids, new_score))\n",
    "\n",
    "        candidates = sorted(candidates, key=lambda x: x[1], reverse=True)[:beam_width]\n",
    "\n",
    "        beam = candidates\n",
    "\n",
    "        iteration = dict()\n",
    "        for i, (candidate_input_ids, candidate_score) in enumerate(beam):\n",
    "            iteration[\"Model\"] = model_name\n",
    "            iteration[\"Input\"] = tokenizer.decode(candidate_input_ids[0], skip_special_tokens=True)\n",
    "\n",
    "            top_tokens = {}\n",
    "            for j in range(choices_per_step):\n",
    "                token_id = top_k_ids[j]\n",
    "                token_prob = top_k_probs[j].item()\n",
    "                top_tokens[f\"Choice {j + 1}\"] = f\"{tokenizer.decode(token_id, skip_special_tokens=True)} ({100 * torch.exp(torch.tensor(token_prob)):.2f}%)\"\n",
    "\n",
    "            iteration.update(top_tokens)\n",
    "\n",
    "        iterations.append(iteration)\n",
    "\n",
    "    df = pd.DataFrame(iterations)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b457ac0a-3788-4bb9-9c44-22b236e27a89",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b7c8b8-8dff-4da9-911d-dd6f36e4b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_bert_df = beam_search_decoding(\"BERT\", bert_model, bert_tokenizer, sentence, n_steps=5, choices_per_step=5, beam_width=5)\n",
    "beam_bert_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9b5ddc-cb1e-4032-b05f-6e5f184bc737",
   "metadata": {},
   "source": [
    "### XLNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fbf32aa-8b5f-4e90-89d7-3b0488ad12b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_xlnet_df = beam_search_decoding(\"XLNET\", xlnet_model, xlnet_tokenizer, sentence, n_steps=5, choices_per_step=5, beam_width=5)\n",
    "beam_xlnet_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc18c411-93c1-448b-afc7-709574a5982d",
   "metadata": {},
   "source": [
    "### XLM-RoBERTa "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da97fd2b-b3e3-4d86-adfb-753ee25323e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_xlmroberta_df = beam_search_decoding(\"XLM-RoBERTa\", xlmroberta_model, xlmroberta_tokenizer, sentence, n_steps=5, choices_per_step=5, beam_width=5)\n",
    "beam_xlmroberta_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3326551-eb5d-41f1-8c78-0a7ed9c67b68",
   "metadata": {},
   "source": [
    "### BART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd21066-b106-4422-9ff3-3e5f2780eb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_bart_df = beam_search_decoding(\"BART\", bart_model, bart_tokenizer, sentence, n_steps=5, choices_per_step=5, beam_width=5)\n",
    "beam_bart_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44d4ba4-8177-4b7b-b0ed-dfb7723a508f",
   "metadata": {},
   "source": [
    "### ELECTRA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f1d1fa-08c5-48ee-a25e-89a320b9906a",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_electra_df = beam_search_decoding(\"ELECTRA\", electra_model, electra_tokenizer, sentence, n_steps=5, choices_per_step=5, beam_width=5)\n",
    "beam_electra_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c9f7c6-53ff-4a28-b527-eab674f09608",
   "metadata": {},
   "source": [
    "### RoBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a018e7-eb5d-4938-8515-654ce7f74229",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_roberta_df = beam_search_decoding(\"RoBERTa\", roberta_model, roberta_tokenizer, sentence, n_steps=5, choices_per_step=5, beam_width=5)\n",
    "beam_roberta_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5968d8ab-90b4-4c2d-a1fc-30aae2d3cf3f",
   "metadata": {},
   "source": [
    "### GPT2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4cd2c7-78ae-4de4-b20a-bd8249b1c9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_gpt2_df = beam_search_decoding(\"GPT2\", gpt2_model, gpt2_tokenizer, sentence, n_steps=5, choices_per_step=5, beam_width=8)\n",
    "beam_gpt2_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2e0952-09f1-45f2-b471-8d0758878635",
   "metadata": {},
   "source": [
    "# Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf8ff26-e569-4d4d-93c0-69069d95ea82",
   "metadata": {},
   "source": [
    "### Greedy Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957e7fe7-5a43-4334-9a55-44e89b914934",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_df = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        greedy_bert_df.loc[4][\"Model\"],\n",
    "        greedy_xlnet_df.loc[4][\"Model\"],\n",
    "        greedy_xlmroberta_df.loc[4][\"Model\"],\n",
    "        greedy_bart_df.loc[4][\"Model\"],\n",
    "        greedy_electra_df.loc[4][\"Model\"],\n",
    "        greedy_roberta_df.loc[4][\"Model\"],\n",
    "        greedy_gpt2_df.loc[4][\"Model\"]\n",
    "    ],\n",
    "    \"Output\": [\n",
    "        greedy_bert_df.loc[4][\"Input\"],\n",
    "        greedy_xlnet_df.loc[4][\"Input\"],\n",
    "        greedy_xlmroberta_df.loc[4][\"Input\"],\n",
    "        greedy_bart_df.loc[4][\"Input\"],\n",
    "        greedy_electra_df.loc[4][\"Input\"],\n",
    "        greedy_roberta_df.loc[4][\"Input\"],\n",
    "        greedy_gpt2_df.loc[4][\"Input\"]\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df058b8e-7092-43dd-a978-1a722e4e9afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "greedy_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac6c669-7d3a-4a66-b0b4-7df9d7c1e1ef",
   "metadata": {},
   "source": [
    "### Beam Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea70d47-462a-4e90-be90-38ec113a8baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_df = pd.DataFrame({\n",
    "    \"Model\": [\n",
    "        beam_bert_df.loc[4][\"Model\"],\n",
    "        beam_xlnet_df.loc[4][\"Model\"],\n",
    "        beam_xlmroberta_df.loc[4][\"Model\"],\n",
    "        beam_bart_df.loc[4][\"Model\"],\n",
    "        beam_electra_df.loc[4][\"Model\"],\n",
    "        beam_roberta_df.loc[4][\"Model\"],\n",
    "        beam_gpt2_df.loc[4][\"Model\"]\n",
    "    ],\n",
    "    \"Output\": [\n",
    "        beam_bert_df.loc[4][\"Input\"],\n",
    "        beam_xlnet_df.loc[4][\"Input\"],\n",
    "        beam_xlmroberta_df.loc[4][\"Input\"],\n",
    "        beam_bart_df.loc[4][\"Input\"],\n",
    "        beam_electra_df.loc[4][\"Input\"],\n",
    "        beam_roberta_df.loc[4][\"Input\"],\n",
    "        beam_gpt2_df.loc[4][\"Input\"]\n",
    "    ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a2dc56-8063-4b66-b6a9-f11dbbc064c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "beam_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5c029f-a447-45df-b396-37740d78ba0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfcce46-a03f-4ae6-9a31-ea614a9eed0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc6edca-c835-4e91-9c33-2680bbf23414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
